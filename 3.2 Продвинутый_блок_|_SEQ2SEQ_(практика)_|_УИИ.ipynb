{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Продвинутый блок | SEQ2SEQ (практика) | УИИ",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adelfos/ds_advanced/blob/main/3.2%20%D0%9F%D1%80%D0%BE%D0%B4%D0%B2%D0%B8%D0%BD%D1%83%D1%82%D1%8B%D0%B9_%D0%B1%D0%BB%D0%BE%D0%BA_%7C_SEQ2SEQ_(%D0%BF%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B0)_%7C_%D0%A3%D0%98%D0%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH1qsHSh9CF7"
      },
      "source": [
        "**Содержание темы**\n",
        "\n",
        "1. [Теория](https://colab.research.google.com/drive/1C72Oa4WU_Tq5lwYfru3lFndo7DD61LSX?)\n",
        "\n",
        "2. Практика\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWZXChuVXHOO"
      },
      "source": [
        "Начните с подключения необходимых библиотек и модулей. В ходе занятия вы подробнее разберете их назначение."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JwSbyp6ldqI"
      },
      "source": [
        "# Подключим модуль для загрузки файлов в colab\n",
        "from google.colab import files\n",
        "\n",
        "# Подключим модуль numpy для работы с массивами\n",
        "import numpy as np\n",
        "\n",
        "# Подгрузим модели кераса\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "\n",
        "# Подключим нужные слои\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input\n",
        "\n",
        "# Поключим оптимайзеры\n",
        "from tensorflow.keras.optimizers import RMSprop, Adadelta\n",
        "\n",
        "# Подключим метод ограничения последовательности заданной длиной\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Подключим токенайзер\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Подключим модуль для one hot кодировки\n",
        "from tensorflow.keras import utils\n",
        "\n",
        "# Подключим визуализацию графа модели\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Подключим модуль для работы с yaml - файлами\n",
        "import yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BsiTmZxlw3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26ea0d41-aa1d-4404-8e24-72dd957a3e75"
      },
      "source": [
        "# Загрузим обучающие тексты\n",
        "\n",
        "!wget  http://www.manythings.org/anki/rus-eng.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-30 11:13:10--  http://www.manythings.org/anki/rus-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.21.92.44, 172.67.186.54, 2606:4700:3033::ac43:ba36, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.21.92.44|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14683939 (14M) [application/zip]\n",
            "Saving to: ‘rus-eng.zip’\n",
            "\n",
            "rus-eng.zip         100%[===================>]  14.00M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-01-30 11:13:10 (124 MB/s) - ‘rus-eng.zip’ saved [14683939/14683939]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjmadRZluEW8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3729a6d-77ce-43c2-96b6-dde0bc1b12d1"
      },
      "source": [
        "# Убедимся, что файл со текстами загружен\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rus-eng.zip  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FFRCgRYtpce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e6e096-f3fd-454a-95e4-11caa51a0294"
      },
      "source": [
        "# Распакуем архив\n",
        "!unzip -o rus-eng.zip "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  rus-eng.zip\n",
            "  inflating: rus.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB0Rc7uHXfjM"
      },
      "source": [
        "Читаем из файла 50000 пар русских и английских предложений. Каждая строка содержит английское, русское предложения и служебные данные об источнике информации. Нам нужны только предложения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl7xc-a2l2UJ"
      },
      "source": [
        "conversations = []                                # Заготовим список для пар фраз\n",
        "\n",
        "with open(\"rus.txt\", 'r', encoding='utf-8') as f: # Открываем файл словаря в режиме чтения\n",
        "    lines = f.read().split('\\n')                  # Читаем весь файл, режем на строки\n",
        "\n",
        "# Цикл по строкам\n",
        "for i,line in enumerate(lines):\n",
        "    \n",
        "    if i>50000:                                         # Нам нужно только 50000 первых строк\n",
        "      break                                             # Заканчиваем цикл\n",
        "    try:\n",
        "        input_text, target_text,_ = line.split(\"\\t\")    # Берем очередную строку, режем по символу табуляции\n",
        "        conversations.append([input_text, target_text]) # Заполняем список пар фраз\n",
        "    except:\n",
        "        continue                                        # если не получается - идем за следущей строкой"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWoO0SPKXpJy"
      },
      "source": [
        "Определим функцию для удаления пробелов перед знаками препинаний. На вход принимает строку или список строк. Выбрасывает пробелы перед знаками препинаний. Возвращает также строку или список строк"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEjCtIubm0WH"
      },
      "source": [
        "def my_replacer(s):  \n",
        "\n",
        "    ''' Функция для удаления пробелов перед знаками препинания\n",
        "\n",
        "        Args: строка или список строк\n",
        "\n",
        "        Returns: строка или список строк\n",
        "    '''\n",
        "\n",
        "    if isinstance(s,str): # Если получили строку\n",
        "\n",
        "        # Убираем перед знаками препинания пробел и возвращаем\n",
        "        return s.replace(' .','.').replace(' ,',',').replace(' !','!').replace(' ?','?')\n",
        "\n",
        "    if isinstance(s,list): # Если получили список\n",
        "        ou=[]              # Заготовим пустой список\n",
        "\n",
        "        for l in s:        # Цикл по строкам из списка\n",
        "            ou.append(l.replace(' .','.').replace(' ,',',').replace(' !','!').replace(' ?','?')) # Убираем перед знаками препинания пробел и возвращаем\n",
        "\n",
        "        # Вернем список строк\n",
        "        return ou    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE5HYfVKX1US"
      },
      "source": [
        "Файл с русскими и английскими выражениями часто может быть поврежден или составлен небрежно. К сожалению так бывает. Фразы могут быть получены автоматически из самых разных текстов, в различных форматах и кодировках. Часто просто нет времени проконтроллировать данных процесс, вычитать полученные предложения. \n",
        "\n",
        "Почистим выражения, добавим тэги `< start >` `< end >` к ответам:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bm0AKcim066",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f3802a-ccc0-4466-da62-9723531d9a93"
      },
      "source": [
        "# Собираем вопросы и ответы в списки\n",
        "\n",
        "questions = [] # Переменная для списка входных фраз\n",
        "answers = []   # Переменная для списка ответных фраз\n",
        "\n",
        "# Цикл по всем парам фраз \n",
        "for con in conversations:                 \n",
        "  \n",
        "    if len(con) > 1 :                       # Если ответная фраза содержит более одно двух предложений\n",
        "        questions.append(my_replacer(con[0])) # То первую в списке фразу отправляем в список входных фраз\n",
        "        replies = my_replacer(con[1:])        # А ответную составляем из последующих строк\n",
        "        ans = ' '.join(replies)               # Здесь соберем ответ\n",
        "        answers.append(ans)                   # Добавим в список ответов\n",
        "    else:\n",
        "        continue                              # Иначе идем на новой парой фраз\n",
        "\n",
        "# Добавим в каждую ответную фразу теги  <START> и <END>\n",
        "answers = ['<START> ' + s + ' <END>' for s in answers]\n",
        "\n",
        "# Выведем обновленные данные на экран\n",
        "print('Вопрос : {}'.format(questions[111])) # Пример входной фразы\n",
        "print('Ответ : {}'.format(answers[111]))    # Пример ответной фразы"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вопрос : Go now.\n",
            "Ответ : <START> Иди сейчас. <END>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(questions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlKmQpfxskql",
        "outputId": "a1408c13-10e4-4e08-9040-de9a01b206f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50001"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G254tOSdYJcj"
      },
      "source": [
        "Создадим токенайзер из библиотеки Keras. В нашем случае токенайзер просто проиндексирует слова по уменьшению частоты появления и  удалит символы \"#$%&()*+-/;<=>@[\\\\]^_`{|}~\\t\\n\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXWLmtgwnf_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc30ead-7170-4424-b74e-2512d819f075"
      },
      "source": [
        "# Создадим токенайзер \n",
        "tokenizer = Tokenizer(filters='\"#$%&()*+-/;<=>@[\\\\]^_`{|}~\\t\\n',split=' ')  \n",
        "\n",
        "# Загружаем в токенизатор список фраз для сборки словаря частотности\n",
        "tokenizer.fit_on_texts(questions + answers)         \n",
        "\n",
        "# Список с cодержимым словаря\n",
        "vocabularyItems = list(tokenizer.word_index.items())    \n",
        "\n",
        "# Размер словаря\n",
        "vocabularySize = len(vocabularyItems)+1        \n",
        "\n",
        "# Выведем фрагмент и размер словаря\n",
        "print( 'Фрагмент словаря : {}'.format(vocabularyItems[:50]))       \n",
        "print( 'Размер словаря : {}'.format(vocabularySize))             "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фрагмент словаря : [('start', 1), ('end', 2), ('я', 3), ('i', 4), ('tom', 5), ('том', 6), ('не', 7), ('это', 8), ('you', 9), ('is', 10), ('a', 11), (\"i'm\", 12), ('ты', 13), ('мы', 14), ('мне', 15), ('the', 16), ('it', 17), ('was', 18), ('we', 19), ('to', 20), ('вы', 21), ('у', 22), ('do', 23), ('it.', 24), ('в', 25), ('он', 26), ('меня', 27), ('tom.', 28), ('my', 29), (\"it's\", 30), ('you.', 31), (\"don't\", 32), ('are', 33), ('can', 34), ('me.', 35), ('did', 36), (\"you're\", 37), ('your', 38), ('he', 39), ('они', 40), ('на', 41), ('был', 42), ('this', 43), ('have', 44), ('что', 45), ('not', 46), ('go', 47), (\"i'll\", 48), ('that', 49), ('be', 50)]\n",
            "Размер словаря : 26464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_2p6ElGYqww"
      },
      "source": [
        "А теперь от слов к цифрам: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7jhZ6I7nj-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28d7035a-86e0-4c4f-d554-b12b9dca6b5e"
      },
      "source": [
        "# Разбиваем текст входных фраз на последовательности индексов\n",
        "tokenizedQuestions = tokenizer.texts_to_sequences(questions)\n",
        "\n",
        "# Уточняем длину самой длинной фразы\n",
        "maxLenQuestions = max([ len(x) for x in tokenizedQuestions])\n",
        "\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие фразы\n",
        "paddedQuestions = pad_sequences(tokenizedQuestions, maxlen=maxLenQuestions, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть, переводим в numpy массив\n",
        "encoderForInput = np.array(paddedQuestions)        \n",
        "\n",
        "# Выведем на экран\n",
        "print('Пример входной фразы                         : {}'.format(questions[100]))         \n",
        "print('Пример кодированной входной фразу            : {}'.format(encoderForInput[100]))  \n",
        "print('Размеры закодированного массива входных фраз : {}'.format(encoderForInput.shape))  \n",
        "print('Установленная длина входных фраз             : {}'.format(maxLenQuestions))        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример входной фразы                         : Freeze!\n",
            "Пример кодированной входной фразу            : [6316    0    0    0    0    0]\n",
            "Размеры закодированного массива входных фраз : (50001, 6)\n",
            "Установленная длина входных фраз             : 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGXX3vrPf4Tg"
      },
      "source": [
        "Те же манипуляции с выходными данными для обучения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic46XLxmnmTS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8617ebc7-9d2f-4229-c741-3c6c6b3a25ee"
      },
      "source": [
        "# Разбиваем текст ответных фраз на последовательности индексов\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) \n",
        "\n",
        "# Уточняем длину самого длинного ответа\n",
        "maxLenAnswers = max([len(x) for x in tokenizedAnswers])\n",
        "\n",
        "# Делаем последовательности одной длины, заполняя нулями более ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть, переводим в numpy массив\n",
        "decoderForInput = np.array(paddedAnswers)               \n",
        "\n",
        "# Выведем на экран\n",
        "print('Пример оригинального ответа на вход: {}'.format(answers[100]))                         \n",
        "print('Пример кодированного ответа на вход : {}'.format(decoderForInput[100][:30]))           \n",
        "print('Размеры кодированного массива ответов на вход : {}'.format(decoderForInput.shape))     \n",
        "print('Установленная длина ответов на вход : {}'.format(maxLenAnswers))                       "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример оригинального ответа на вход: <START> Ни с места! <END>\n",
            "Пример кодированного ответа на вход : [    1  1058    60 11561     2     0     0     0     0     0     0     0]\n",
            "Размеры кодированного массива ответов на вход : (50001, 12)\n",
            "Установленная длина ответов на вход : 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6rTRqXQhd_j"
      },
      "source": [
        "Те же манипуляции с выходными данными для проверки. Убирает тег `< start >`. \n",
        "\n",
        "Сетка не будет выдавать фразы с этим тэгом, поэтому и контрольные фразы должны быть без него: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG6zfN2ZnoR_"
      },
      "source": [
        "# Разбиваем текст ответов на последовательности индексов\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) \n",
        "\n",
        "for i in range(len(tokenizedAnswers)) :                  # Для разбитых на последовательности ответов\n",
        "    tokenizedAnswers[i] = tokenizedAnswers[i][1:]          # Избавляемся от тега <START>\n",
        "\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers , padding='post') \n",
        "\n",
        "# И сохраняем в виде массива numpy\n",
        "decoderForOutput = np.array(paddedAnswers)                                             "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8MeXs5NnrDI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6dccaa-c7bf-402e-eac4-c83a8a267802"
      },
      "source": [
        "# Выведем на экран\n",
        "\n",
        "print('Пример кодированного ответа на вход : {}'.format(decoderForInput[100][:21]))   \n",
        "print('Пример кодированного ответа на выход : {}'.format(decoderForOutput[100][:21]))\n",
        "print('Размеры кодированного массива ответов на выход : {}'.format(decoderForOutput.shape))  \n",
        "print('Установленная длина вопросов на выход : {}'.format(maxLenAnswers))                    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример кодированного ответа на вход : [    1  1058    60 11561     2     0     0     0     0     0     0     0]\n",
            "Пример кодированного ответа на выход : [ 1058    60 11561     2     0     0     0     0     0     0     0     0]\n",
            "Размеры кодированного массива ответов на выход : (50001, 12)\n",
            "Установленная длина вопросов на выход : 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z97aBK_UZDH8"
      },
      "source": [
        "Создадим энкодер. Он состоит из входного слоя, Embedding-а и одной LSTM. \n",
        "\n",
        "На его вход будет подавать предложение,  которое нужно перевести. На выходе - векторы состояния. Они являются исходной информацией для декодера."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDNMte7cns1A"
      },
      "source": [
        "# Создадим энкодер \n",
        "\n",
        "encoderInputs = Input(shape=(None , ))                                             # Добавим входной слой\n",
        "encoderEmbedding = Embedding(vocabularySize, 200 , mask_zero=True)(encoderInputs)  # Добавим эмбеддинг\n",
        "encoderOutputs, state_h , state_c = LSTM(200, return_state=True)(encoderEmbedding) # Добавим LSTM\n",
        "encoderStates = [state_h, state_c]                                                 # Соберем выходы lstm  в список    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN9oz5HVZ5DN"
      },
      "source": [
        "Вторая часть нейронки - это декодер. Он также содержит входной слой, Embedding и одну LSTM. \n",
        "\n",
        "На входе обучающая фраза, на выходе предсказанное слово - в виде длинного-длинного массива One-Hot-Encoding (OHE). \n",
        "\n",
        "Массив выглядит `'0,0,0,0,1,0,0,0,0,0,0'`, где позиция единички указывает на индекс слова, присвоенный токенайзером"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y9Y9ZqrnwLu"
      },
      "source": [
        "# Создадим декодер \n",
        "\n",
        "decoderInputs = Input(shape=(None, ))                                                # Добавим входной слой\n",
        "decoderEmbedding = Embedding(vocabularySize, 200, mask_zero=True) (decoderInputs)    # Добавим эмбеддинг\n",
        "decoderLSTM = LSTM(200, return_state=True, return_sequences=True)                    # Создадим LSTM слой\n",
        "decoderOutputs , _ , _ = decoderLSTM (decoderEmbedding, initial_state=encoderStates) # Прогоним выход embedding через LSTM\n",
        "decoderDense = Dense(vocabularySize, activation='softmax')                           # Создадим dense слой\n",
        "output = decoderDense (decoderOutputs)                                               # Прогоним  выход LSTM через DENSE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvdnneyzbe_D"
      },
      "source": [
        "Пора собирать кодер и декодер вместе. \n",
        "\n",
        "Посмотрим на структуру построенный сети. Заметим, что при обучении будем минимизировать sparse_categorical_crossentropy. \n",
        "\n",
        "Часто, при предсказании дискретных классов используют известную вам categorical_crossentropy. Для ее использовании слова обучающей выборки слова  необходимо преобразовывать в OHE. Все бы хорошо, но для хранения одного слова придется потратить очень много памяти. Вместо одного значения - 1 единицу и кучу нулей, по числу возможных слов. \n",
        "\n",
        "Sparse_categorical_crossentropy - позволяет хранить 1 токен. При обучении он сам развернет обучающее слово в OHE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nUYagRLnwko"
      },
      "source": [
        "# Собираем модель\n",
        "\n",
        "model = Model([encoderInputs, decoderInputs], output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLDHVdcIoltf"
      },
      "source": [
        "# Компилиуем модель\n",
        "\n",
        "model.compile(optimizer=RMSprop(), loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usHiPpGzojZ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ad577aa-f3ab-4526-afa9-a210dde0b2df"
      },
      "source": [
        "# Выведем на экран информацию о построенной модели нейросети\n",
        "\n",
        "print(model.summary())  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, None, 200)    5292800     ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, None, 200)    5292800     ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 200),        320800      ['embedding_2[0][0]']            \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 200),  320800      ['embedding_3[0][0]',            \n",
            "                                 (None, 200),                     'lstm_2[0][1]',                 \n",
            "                                 (None, 200)]                     'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 26464)  5319264     ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 16,546,464\n",
            "Trainable params: 16,546,464\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqM1TJgUogeF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "c120777a-d750-4cee-fe75-dfde19340d44"
      },
      "source": [
        "# Построим график для визуализации слоев и связей между ними\n",
        "\n",
        "plot_model(model, to_file='model.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvT72V_0bpCN"
      },
      "source": [
        "Пора обучаться. И не забудем сохранить обученную модель на диске"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcT0PuS9nysP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a99b97d7-ab6c-4861-e2ce-12516121b646"
      },
      "source": [
        "# Запустим обучение\n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=256, epochs=30) \n",
        "\n",
        "# Сохраним модель на диске\n",
        "model.save( 'content/model_30epochs(rms).h5' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "196/196 [==============================] - 8s 40ms/step - loss: 0.4792\n",
            "Epoch 2/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.4710\n",
            "Epoch 3/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.4622\n",
            "Epoch 4/30\n",
            "196/196 [==============================] - 8s 40ms/step - loss: 0.4532\n",
            "Epoch 5/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.4453\n",
            "Epoch 6/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.4393\n",
            "Epoch 7/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.4331\n",
            "Epoch 8/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.4270\n",
            "Epoch 9/30\n",
            "196/196 [==============================] - 8s 40ms/step - loss: 0.4214\n",
            "Epoch 10/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.4156\n",
            "Epoch 11/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.4101\n",
            "Epoch 12/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.4043\n",
            "Epoch 13/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.3986\n",
            "Epoch 14/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.3920\n",
            "Epoch 15/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.3859\n",
            "Epoch 16/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.3806\n",
            "Epoch 17/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.3754\n",
            "Epoch 18/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.3710\n",
            "Epoch 19/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.3661\n",
            "Epoch 20/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.3613\n",
            "Epoch 21/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.3566\n",
            "Epoch 22/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.3518\n",
            "Epoch 23/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.3470\n",
            "Epoch 24/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.3423\n",
            "Epoch 25/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.3372\n",
            "Epoch 26/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.3324\n",
            "Epoch 27/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.3283\n",
            "Epoch 28/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.3239\n",
            "Epoch 29/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.3193\n",
            "Epoch 30/30\n",
            "196/196 [==============================] - 8s 39ms/step - loss: 0.3148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQpGBXUNvfGC"
      },
      "source": [
        "# Сохраним веса модели\n",
        "model.save_weights('s2s_30epochs.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dp6nuHCb4E6"
      },
      "source": [
        "Уменьшающиеся при обучении лоссы - это хорошо, но оценить качество переведенных фраз может (пока что)  человек -  носитель языка.\n",
        "Давайте перестроим нашу модель для перевода."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9xFNMwBpU2P"
      },
      "source": [
        "Создадим рабочие модели для перевода.\n",
        "\n",
        "В теле функции производится сборка сети для перевода фраз из уже обученных слоев.\n",
        "\n",
        "1. Энкодер оставляем как есть  для задачи seq2seq он не меняется\n",
        "2. Декодеру на вход подаем финальные состояния энкодера.Пропускаем через предобученный ранее LSTM и Dense слои\n",
        "Возвращает модели энкодера и декодера"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pbCDz6In033"
      },
      "source": [
        "def makeInferenceModels():\n",
        "\n",
        "    ''' Функция сборки сети для перевода фраз из уже обученных слов\n",
        "\n",
        "        Args: -\n",
        "\n",
        "        Returns: модели энкодера и декодера   \n",
        "    '''    \n",
        "\n",
        "    # Создадим модель кодера, на входе далее будут закодированные вопросы, на выходе состояния state_h, state_c\n",
        "    encoderModel = Model(encoderInputs, encoderStates) \n",
        "\n",
        "    # Создадим модель декодера\n",
        "    decoderStateInput_h = Input(shape=(200 ,)) # Добавим входной слой для state_h\n",
        "    decoderStateInput_c = Input(shape=(200 ,)) # Добавим входной слой для state_c\n",
        "\n",
        "    # Соберем оба inputs вместе и запишем в decoderStatesInputs\n",
        "    decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c] \n",
        "\n",
        "    # Берём ответы, прошедшие через эмбединг, вместе с состояниями и подаём LSTM cлою\n",
        "    decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding, initial_state=decoderStatesInputs) \n",
        "    \n",
        "    # LSTM даст нам новые состояния\n",
        "    decoderStates = [state_h, state_c]            \n",
        "    \n",
        "    # И ответы, которые мы пропустим через полносвязный слой с софтмаксом\n",
        "    decoderOutputs = decoderDense(decoderOutputs) \n",
        "\n",
        "    # Определим модель декодера, на входе далее будут раскодированные ответы (decoderForInputs) и состояния\n",
        "    # на выходе предсказываемый ответ и новые состояния\n",
        "    decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "\n",
        "    # Вернем рабочие модели энкодера и декодера  \n",
        "    return encoderModel , decoderModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w1SdrcZWAHn"
      },
      "source": [
        "Сервисная функция для перевода произвольной фразы в токены. Функция разбирает фразу на слова. Для каждого слова находит свой индекс. Его подскажет токенайзер. И дополняет полученный список индексов нулями до максимальной длины.\n",
        "Используется для подготовки фразы к ее переводу.\n",
        "Принимает на вход строку, отдает список токенов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzsCtJfFn261"
      },
      "source": [
        "def strToTokens(sentence: str):      \n",
        "\n",
        "    ''' Функция для удаления пробелов перед знаками препинания\n",
        "\n",
        "        Args: фраза\n",
        "\n",
        "        Returns: список токенов\n",
        "    '''\n",
        "\n",
        "    # Почистим фразу\n",
        "    tmp_sent = my_replacer(sentence)  \n",
        "    \n",
        "    # Приведем предложение к нижнему регистру и разбирает на слова\n",
        "    words = tmp_sent.lower().split()  \n",
        "    \n",
        "    # Создадим список для последовательности токенов/индексов\n",
        "    tokensList = list()               \n",
        "\n",
        "    # Для каждого слова в предложении\n",
        "    for word in words:\n",
        "        \n",
        "        try:\n",
        "            tokensList.append(tokenizer.word_index[word]) # Определяем токенайзером индекс и добавляем в список\n",
        "        except:\n",
        "            pass # Слова нет - просто игнорируем его\n",
        "\n",
        "    # Вернёт входную фразу в виде последовательности индексов\n",
        "    if tokensList:\n",
        "        return pad_sequences([tokensList], maxlen=maxLenQuestions , padding='post')\n",
        "\n",
        "    # Фраза из незнакомых слов - вернем None \n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6Oa6j7Fe9Ye",
        "outputId": "2a297b30-8fa2-474a-d4c0-28de12efaca0"
      },
      "source": [
        "import numpy as np\n",
        "emptyTargetSeq = np.zeros((1, 1))\n",
        "\n",
        "\n",
        "emptyTargetSeq[0, 0] = 5\n",
        "\n",
        "emptyTargetSeq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXtp9Yc1dHWm"
      },
      "source": [
        "Запускаем функцию для построения модели кодера и декодера"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FLuVC7XsIGI"
      },
      "source": [
        "encModel , decModel = makeInferenceModels() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeujebMKcT5m"
      },
      "source": [
        "Начинаем перевод текстов. Нейронка попросит на вход 6 (лучше простеньких) фраз и выдаст то, что она об этом думает. Работаем в цикле.\n",
        "\n",
        "Начнем с подготовки:\n",
        "\n",
        "- Сначала запросим фразу у пользователя, переведем ее в токены при помощи функции `strToTokens()` и поместим результат в переменную `qua`. \n",
        "- Проверим, не состоит ли фраза из полностью незнакомых слов.\n",
        "- Создадим массив `emptyTargetSeq` вида [[0.]], поместим в его начало слово `start` в виде индекса. \n",
        "- Определим условие остановки генерации `stopCondition` \n",
        "- Создадим переменную `decodedTranslation` для сборки ответа\n",
        "- Прогоним фразу через энкодер и поместим результат в переменную `statesValues`\n",
        "\n",
        "Далее, пока не сработало стоп-условие, в модель декодера подаем пустую последовательность со словом 'start' и состояния, предсказанные кодером по заданному вопросу. Декодер заменит слово 'start' предсказанным сгенерированным словом и обновит состояния. Поместим результат в переменные `decOutputs , h , c`.\n",
        "\n",
        "Обработаем предсказанное слово функцией `np.argmax`, получим его индекс и поместим резуьтат в переменную `sampledWordIndex`.\n",
        "\n",
        "Создадим переменную `sampledWord` для слов, преобразованных в естественный язык.\n",
        "\n",
        "Переберем в цикле все индексы токенайзера, и если индекс выбранного слова соответствует какому-то индексу из словаря, то слово, идущее под этим индексом в словаре, добавляется в итоговый ответ. Плюс выбранное слово фиксируем в переменную sampledWord. Если выбранным словом оказывается 'end' либо если сгенерированный ответ превышает заданную максимальную длину ответа - срабатывает стоп-условие и прекращаем генерацию.\n",
        "\n",
        "Создаем пустой массив, заносим в него индекс выбранного слова. Сохраняем в список `statesValues` состояния, обновленные декодером.\n",
        "\n",
        "Выводим ответ сгенерированный декодером."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B9sAeCNM8UQ",
        "outputId": "de0d45df-2539-42e5-9d8f-8bf163902d05"
      },
      "source": [
        "# Цикл по количеству входных фраз - их 6\n",
        "\n",
        "for _ in range(6):\n",
        "\n",
        "    # подготовка\n",
        "    \n",
        "    qua  = strToTokens(input('Исходное предложение на английском: '))\n",
        "    if qua is None:                                      \n",
        "        print (\"а вот спросите меня о чем-нить полезном: \")  # Выдадим дежурную фразу\n",
        "        continue                                             # Пойдем за следущей фразой\n",
        "\n",
        "    emptyTargetSeq = np.zeros((1, 1))                    \n",
        "    emptyTargetSeq[0, 0] = tokenizer.word_index['start'] \n",
        "    stopCondition = False                                \n",
        "    decodedTranslation = '' \n",
        "    statesValues = encModel.predict(qua)                              \n",
        "\n",
        "    # пока не сработало стоп-условие\n",
        "    while not stopCondition:                             \n",
        "\n",
        "        # В модель декодера подадим пустую последовательность со словом 'start' и состояния\n",
        "        decOutputs , h , c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "        # Получим индекс предсказанного слова.\n",
        "        sampledWordIndex = np.argmax( decOutputs[0, 0, :]) \n",
        "        # Создаем переменную для преобразованных на естественный язык слов\n",
        "        sampledWord = None                                 \n",
        "\n",
        "        # Переберем в цикле все индексы токенайзера\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "        \n",
        "            # Если индекс выбранного слова соответствует какому-то индексу из словаря\n",
        "            if sampledWordIndex == index:              \n",
        "                # Слово, идущее под этим индексом в словаре, добавляется в итоговый ответ \n",
        "                decodedTranslation += ' {}'.format(word) \n",
        "                # Выбранное слово фиксируем в переменную sampledWord\n",
        "                sampledWord = word                       \n",
        "        \n",
        "        # Если выбранным словом оказывается 'end' либо если сгенерированный ответ превышает заданную максимальную длину ответа\n",
        "        if sampledWord == 'end' or len(decodedTranslation.split()) > maxLenAnswers:\n",
        "            stopCondition = True # Срабатывает стоп-условие и прекращаем генерацию\n",
        "\n",
        "        # Создаем пустой массив\n",
        "        emptyTargetSeq = np.zeros((1, 1))       \n",
        "        \n",
        "        # Заносим в него индекс выбранного слова\n",
        "        emptyTargetSeq[0, 0] = sampledWordIndex \n",
        "        \n",
        "        # Записываем состояния, обновленные декодером \n",
        "        statesValues = [h, c]   \n",
        "\n",
        "        # И продолжаем цикл с обновленными параметрами                \n",
        "                                                \n",
        "    # Выводим ответ сгенерированный декодером\n",
        "    print(\"Перевод: \", decodedTranslation) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходное предложение на английском: what is your name?\n",
            "Перевод:   как твоё имя? end\n",
            "Исходное предложение на английском: How are you?\n",
            "Перевод:   как у вас дела? end\n",
            "Исходное предложение на английском: what are you doing?\n",
            "Перевод:   что ты будешь делает? end\n",
            "Исходное предложение на английском: how old are you?\n",
            "Перевод:   сколько вам лет? end\n",
            "Исходное предложение на английском: what is your mood today?\n",
            "Перевод:   как твой имя? end\n",
            "Исходное предложение на английском: are you angry?\n",
            "Перевод:   ты злишься? end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFc-MoTjqs5X"
      },
      "source": [
        "Что сказать... Фразы подчас смешные, но общий смысл уже где-то рядом..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZO3qjIF9Njp"
      },
      "source": [
        "**Содержание темы**\n",
        "\n",
        "1. [Теория](https://colab.research.google.com/drive/1C72Oa4WU_Tq5lwYfru3lFndo7DD61LSX?authuser=1#scrollTo=nH1qsHSh9CF7)\n",
        "\n",
        "2. Практика\n"
      ]
    }
  ]
}