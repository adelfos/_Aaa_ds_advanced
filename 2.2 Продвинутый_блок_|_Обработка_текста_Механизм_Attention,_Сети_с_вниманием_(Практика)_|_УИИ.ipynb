{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Продвинутый блок | Обработка текста. Механизм Attention, Сети с вниманием (Практика) | УИИ",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adelfos/ds_advanced/blob/main/2.2%20%D0%9F%D1%80%D0%BE%D0%B4%D0%B2%D0%B8%D0%BD%D1%83%D1%82%D1%8B%D0%B9_%D0%B1%D0%BB%D0%BE%D0%BA_%7C_%D0%9E%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B0_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0_%D0%9C%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%B7%D0%BC_Attention%2C_%D0%A1%D0%B5%D1%82%D0%B8_%D1%81_%D0%B2%D0%BD%D0%B8%D0%BC%D0%B0%D0%BD%D0%B8%D0%B5%D0%BC_(%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B0)_%7C_%D0%A3%D0%98%D0%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CisjvJh3bdIw"
      },
      "source": [
        "**Содержание темы**\n",
        "\n",
        "1. [Теория](https://colab.research.google.com/drive/1Bg-UmpEz-T1HcH1CYXH7F4CwJF6asDwa?usp=sharing#scrollTo=ApEBBKSZbVv8)\n",
        "\n",
        "2. Практика\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XhodKqwLjQ6"
      },
      "source": [
        "Разберем обучение более подробно на примере готовой сети."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7LxGv5bdgmN"
      },
      "source": [
        "# модуль для загрузки файлов в colab\n",
        "from google.colab import files \n",
        "\n",
        "# Подключим tensorflow\n",
        "import tensorflow as tf \n",
        "\n",
        "# Подключим токенайзер\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Используем метод для формирования последовательностей одинаковой длины\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
        "\n",
        "# Загружаем абстрактный класс базовой модели сети от кераса\n",
        "from tensorflow.keras.models import Model \n",
        "\n",
        "# Подключим необходимые слои\n",
        "from tensorflow.keras.layers import Dense, Embedding, GRU\n",
        "\n",
        "# Подключим оптимайзер\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "\n",
        "# Подключим функцию потерь\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "# Подключим numpy - библиотеку для работы с массивами данных\n",
        "import numpy as np \n",
        "\n",
        "# Подключим библиотеку для визуализации данных\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# Подключим модуль для определения форматирования и местоположения делений на осях графиков\n",
        "import matplotlib.ticker as ticker \n",
        "\n",
        "# Подключим модуль для разбивки данных на обучающую и тестовую выборки\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# Подключим модуль для работы с регулярными выражениями\n",
        "import re \n",
        "\n",
        "# Подключим модуль для работы с временем\n",
        "import time\n",
        "\n",
        "# Подключим модуль для работы с операционной системой\n",
        "import os "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjqYknxCqmX8",
        "outputId": "ade907f1-f136-477e-c4d9-93f91835d2f2"
      },
      "source": [
        "# Скачаем датасет из пар фраз на русском и английском языках \n",
        "!wget  http://www.manythings.org/anki/rus-eng.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-03 16:45:42--  http://www.manythings.org/anki/rus-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.21.92.44, 172.67.186.54, 2606:4700:3030::6815:5c2c, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.21.92.44|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14385451 (14M) [application/zip]\n",
            "Saving to: ‘rus-eng.zip’\n",
            "\n",
            "rus-eng.zip         100%[===================>]  13.72M  8.70MB/s    in 1.6s    \n",
            "\n",
            "2021-10-03 16:45:45 (8.70 MB/s) - ‘rus-eng.zip’ saved [14385451/14385451]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGGoRhuVyd_W"
      },
      "source": [
        "Распакуем скачанные тексты и убедимся в появлении файла со словарем:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VlOfx4jtB9e",
        "outputId": "26c8b71b-f346-4074-dedf-8bcd6ed0345b"
      },
      "source": [
        "!unzip -o rus-eng.zip "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  rus-eng.zip\n",
            "  inflating: rus.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHBPiDxa9_Mg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7fcf94d-9d4a-4778-abfc-1f165559b3dd"
      },
      "source": [
        "# Проверим распакованные файлы\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_about.txt  rus-eng.zip  rus.txt  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O7TDn54-ATt"
      },
      "source": [
        "# Определим переменную с именем файла с датасетом\n",
        "path_to_file=\"rus.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGAVJe9iynJi"
      },
      "source": [
        "Определим функцию для подготовки предложений из словаря для обучения нейронной  сети. Добавим пробелы между словами и знаками препинаний, служебные символы заменим на пробелы, уберем пробелы в начале и конце фразы., добавим тег `< start >` в начало фразы, `< end >` в конец:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWA1mr0Rqq_9"
      },
      "source": [
        "def preprocess_sentence(phrases): # Функция принимает содержимое словаря\n",
        "\n",
        "  # Разделяем пробелами слова и знаки препинания(\"А как насчет тебя? \" -> \"А как насчет тебя ? \") \n",
        "  phrases = re.sub(r\"([?.!,;:])\", r\" \\1 \", phrases) # r\" \\1 \" берёт значения 1й группы в скобках; обрамляем указанные символы пробелами\n",
        "\n",
        "  # Заменяем всё на пробелы, за исключением (a-zA-Zа-яёА-ЯЁ?.!,;:)\n",
        "  phrases = re.sub(r\"[^a-zA-Zа-яёА-ЯЁ?.!,;:]+\", \" \", phrases) \n",
        "  \n",
        "  # Получаем строку без случайных лишних пробелов в конце фраз(rstrip удаляет с конца строки)\n",
        "  phrases = phrases.rstrip().strip()      \n",
        "\n",
        "  # Для нашей модели обозначим тегами начало и конец предложения  \n",
        "  phrases = '<start> ' + phrases + ' <end>' \n",
        "\n",
        "  # Функция возвращает предобработанные фразы\n",
        "  return phrases "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKj6v9AIvdSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "137b2a75-582d-4d35-83a4-feee1331546f"
      },
      "source": [
        "# Покажем пример обработки фразц\n",
        "\n",
        "print(\"Фразы после обработки функцией с т.з. пунктуации примут вид:\") \n",
        "print(preprocess_sentence(\"What about you?\"))                         # Выведем пример до обработки \n",
        "print(preprocess_sentence(\"А как насчет тебя?\"))                      # И после"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фразы после обработки функцией с т.з. пунктуации примут вид:\n",
            "<start> What about you ? <end>\n",
            "<start> А как насчет тебя ? <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWrBY276Oyb-"
      },
      "source": [
        "Перегоним фразы в датасет. Он представляет список пар из русского и английского предложения. Будем использовать только первые num_examples пар"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5zJhQmqvyNC"
      },
      "source": [
        "Создадим функцию по формированию датасета. На вход принимает путь к файлу с датасетом и требуемый размер датасета. Читает файл построчно и на выходе формирует список пар фраз."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRaVcSowqr9e"
      },
      "source": [
        "# Функция создания датасета\n",
        "\n",
        "def create_dataset(path,          # Путь к файлу\n",
        "                   num_examples): # Необходимый размер датасета \n",
        "\n",
        "  # Открываем файл и разбиваем фразы на отдельные строчки\n",
        "  lines = open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  # В каждой строке словаря разделяем английскую фразу от русской, и пропускаем через функцию предобработки данных\n",
        "  word_pairs = [[preprocess_sentence(phrases) for phrases in l.split('\\t')[0:2]]  for l in lines[:num_examples]]\n",
        "\n",
        "  # Вернем пары фраз в виде [по-английски, по-русски]\n",
        "  return zip(*word_pairs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5iuvrauv4KN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3140b56c-5b7a-4385-c609-8f0ebdb37f33"
      },
      "source": [
        "print(\"Взглянем на пример пары фраз на выходе функции:\")\n",
        "\n",
        "english, russian = create_dataset(path_to_file,40000) # Вызовем функцию для демонстрации\n",
        "print(english[-1])                                    # Выведем последний элемент из списка английских фраз\n",
        "print(russian[-1])                                    # Выведем последний элемент из списка русских фраз"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Взглянем на пример пары фраз на выходе функции:\n",
            "<start> He pleaded guilty . <end>\n",
            "<start> Он признал себя виновным . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plOf8RMSPSz-"
      },
      "source": [
        "Создадим функцию для получения максимальной длины фразы из списка. На вход принимает список фраз. Перебирает список, выбираем максимальное значение длины"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5xw1cPZqu5d"
      },
      "source": [
        "# Создадим мини-функцию, возвращающую максимальную длину тензора\n",
        "def max_length(tensor): # Функция принимает на вход тензор(фразы в виде последовательности индексов)\n",
        "\n",
        "  # Вернем значение максимальной длины его элемента \n",
        "  return max(len(t) for t in tensor) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg-GwLJoPtyJ"
      },
      "source": [
        "Функция преобразовывает тексты в последовательности индексов. \n",
        "Используем стандартный токенайзер из модуля Keras. На вход принимает текст, обучает на нем токенайзер. Переводит текст в токены. Отдает полученые токены и токенайзер"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTLSJIakPmEz"
      },
      "source": [
        "def tokenize(language): # Функция принимает текст одного из языков\n",
        "\n",
        "  language_tokenizer = Tokenizer(filters='')               # Вызываем класс Токенизатор, просим его не удалять символы, которые он удаляет по умолчанию\n",
        "  language_tokenizer.fit_on_texts(language)                # \"скармливаем\" ему тексты для обработки и сборки словаря частотности\n",
        "  tensor = language_tokenizer.texts_to_sequences(language) # Разбиваем текст фраз на последовательности индексов\n",
        "  tensor = pad_sequences(tensor, padding='post')           # Делаем последовательности фиксированной длины, заполняя нулями более короткие фразы\n",
        "\n",
        "  # Возвращаем последовательность индексов(назовем ее тензор) и токенизатор\n",
        "  return tensor, language_tokenizer "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNNNJMfvQBP6"
      },
      "source": [
        "Функция формирующая готовый датасет. Получает на вход путь к файлу с текстами и необходимый размер готового датасета\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaKt_YpuPmbQ"
      },
      "source": [
        "def load_dataset(path,               # Путь к файлу с текстами\n",
        "                 num_examples=None): # Необходимый объем датасета\n",
        "\n",
        "    # Из исходного текста делаем датасет пар фраз, причём входным языком для сети сделаем русский\n",
        "    targ_language, inp_language = create_dataset(path, num_examples)\n",
        "\n",
        "    # Разбиваем текст на последовательность индексов(назовем ее тензор)\n",
        "    input_tensor, inp_language_tokenizer = tokenize(inp_language)    # Формируем тензоры и токенизатор для русского языка\n",
        "    target_tensor, targ_language_tokenizer = tokenize(targ_language) # Формируем тензоры и токенизатор для английского языка\n",
        "\n",
        "    # Функция вернёт: тензор для русского языка, для английского языка; токенизаторы для русского и английского языков\n",
        "    return input_tensor, target_tensor, inp_language_tokenizer, targ_language_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqAYnjBzQMeO"
      },
      "source": [
        "Формируем датасет заданного объема - 40000 (в зависимости от приоритета скорости либо качества обучения), используем ранее написанные функции:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPfw_d52qxtK"
      },
      "source": [
        "num_examples = 40000 # Выберем 40 тысяч строк(всего в базе около 360тысяч строк, в каждой пара фраз)\n",
        "\n",
        "input_tensor, target_tensor, inp_language_tokenizer, targ_language_tokenizer = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Вычислим максимальные длины тензоров для английского и русского языков, используя ранее заданную функцию\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
        "\n",
        "# Создаем тренировочную и тестовую выборки по формуле 80/20\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UCqJHiw5ikC"
      },
      "source": [
        "Создадим вспомогательную функцию для вывода слова фразы и его индекса. На вход подаются токенайзер и фраза:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_Xhk8pb5byY"
      },
      "source": [
        "# Визуализируем собранные данные\n",
        "\n",
        "def convert(language_tokenizer,  # Токенайзер\n",
        "            tensor):             # Список индексов слов\n",
        "            \n",
        "  #  Цикл по токенам во фразе\n",
        "  for t in tensor:  \n",
        "    if t!=0:                                                        # Если токен не 0. Т.е. не мусор в конце фразы\n",
        "      print (\"%d ----> %s\" % (t, language_tokenizer.index_word[t])) # Выводи токен и соответствующее слово\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6tkpocE6X_3"
      },
      "source": [
        "Посмотрим на примеры\n",
        "В первом блоке выведем русскую фразу и ее токен\n",
        "Во втором агнлийскую.\n",
        "\n",
        "Далее выводим статистику по датасету"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2XeriQf5fVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e12f797-3c5f-4e84-edfe-e3409320edba"
      },
      "source": [
        "print (\"Фраза на русском языке; соответствие индекса и слова\")   \n",
        "convert(inp_language_tokenizer, input_tensor_train[0])           # Выведем нулевую пару из русского датасета\n",
        "print ()    \n",
        "\n",
        "print (\"Фраза на английском языке; соответствие индекса и слова\")\n",
        "convert(targ_language_tokenizer, target_tensor_train[0])         # Выведем нулевую пару из агнлийского датасета\n",
        "print ()   \n",
        "                                                      \n",
        "print(\"Рус.яз. тренировочная: \" , len(input_tensor_train), \"фраз; \", \"Анг.яз. тренировочная: \", len(target_tensor_train), \"фраз\")# Выведем статистику по обучающей выборке\n",
        "print(\"Рус.яз. тестовая: \", len(input_tensor_val), \"фраз; \", \"Анг.яз. тестовая: \", len(target_tensor_val), \"фраз\")               # Выведем статистику по тестовой выборке"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фраза на русском языке; соответствие индекса и слова\n",
            "1 ----> <start>\n",
            "11 ----> мы\n",
            "197 ----> оба\n",
            "166 ----> видели\n",
            "18 ----> тома\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Фраза на английском языке; соответствие индекса и слова\n",
            "1 ----> <start>\n",
            "14 ----> we\n",
            "155 ----> both\n",
            "85 ----> saw\n",
            "5 ----> tom\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Рус.яз. тренировочная:  32000 фраз;  Анг.яз. тренировочная:  32000 фраз\n",
            "Рус.яз. тестовая:  8000 фраз;  Анг.яз. тестовая:  8000 фраз\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3AgPtOj83H9"
      },
      "source": [
        "Создаем `tf.data` датасет (Раздел `tf.data.Dataset API` предлагает построить готовый конвейер для обучения моделей)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuEJJsHy9rp5"
      },
      "source": [
        "# Определим постоянные \n",
        "\n",
        "BUFFER_SIZE = len(input_tensor_train)                     # Укажем что случайно сэмплировать будем по всей длине обучающейся выборки\n",
        "BATCH_SIZE = 256                                          # Указываем размер батча\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE     # Укажем количество шагов в одной эпохе\n",
        "embedding_dim = 256                                       # Размерность эмбеддинга, векторного пространства\n",
        "units = 1024                                              # Задаем размер слоя(количество нейронов в слое) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB82awfvDB6o"
      },
      "source": [
        "# Задаем размер русского словаря\n",
        "vocab_inp_size = len(inp_language_tokenizer.word_index)+1 \n",
        "\n",
        "# Задаем размер английского словаря\n",
        "vocab_tar_size = len(targ_language_tokenizer.word_index)+1 \n",
        "\n",
        "# Создаём датасет из массивов Numpy(рус и анг тренировочные фразы) со случайной подачей тренировочных сэмплов в процессе обучения\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "\n",
        "# Передаем в датасет размер батча и указываем, что если в тренировке последний батч окажется неполным, то опустим его\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDgb_Z7y98ir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d2c12dd-d999-4139-c90d-0f80a7dd53af"
      },
      "source": [
        "# Посмотрим на форму примеров полученных батчей\n",
        "\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([256, 12]), TensorShape([256, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZE7WSCKQ4-H"
      },
      "source": [
        "Вспомним нашу схему - сеть состоит их кодера, декодера и блока attention.\n",
        "\n",
        "Давайте начнем оформлять кодер в виде класса. В этом примере кодер состоит из блоков `Embedding` и `GRU`. Обратим внимание на `return_sequences=True`, `return_state=True` - мы требуем состояния кодера на каждом шаге работы. \n",
        "\n",
        "На вход принимает фразу для перевода и начальное состояние. Отдает выход GRU и вектор скрытых состояний"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJwqiGRCDCu1"
      },
      "source": [
        "class Encoder(Model):\n",
        "\n",
        "  # Конструктор класса \n",
        "  def __init__(self, \n",
        "               vocab_size,    # Размер словаря\n",
        "               embedding_dim, # Размер пространсва эмбеддинга\n",
        "               enc_units,     # Число нейронов в GRU\n",
        "               batch_sz):     # Размер батча\n",
        "\n",
        "    super(Encoder, self).__init__()                                   # Даем возможность использовать и исполнять методы класса-родителя в классе потомке \n",
        "    self.batch_sz = batch_sz                                          # Атрибут возвращает размер батча\n",
        "    self.enc_units = enc_units                                        # Атрибут возвращает размер слоя в кодировщике\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim)             # Атрибут эмбеддинга - слой Кераса с размером словаря на входе и с dim=256\n",
        "\n",
        "    # Реккурентной сетью выберем GRU, указываем размер слоя, вывод из слоя в виде последовательностей, \n",
        "    # и метод инициализации весов 'glorot_uniform'(или метод Ксавьера) для упрощения прохождения сигнала при распростр-ии ошибки\n",
        "    self.gru = GRU(self.enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  # Метод принимает входную фразу и начальное состояние\n",
        "  def call(self, \n",
        "           x,       # Входная фраза\n",
        "           hidden): # Начальное энкодера\n",
        "    x = self.embedding(x) # входящие тензоры преобразовываются в эмбеддинг\n",
        "    output, state = self.gru(x, initial_state = hidden) #затем пропускаются через GRU и получаем выход + новое состояние\n",
        "\n",
        "    # Выход сети GRU и состояние на выходе\n",
        "    return output, state \n",
        "\n",
        "  # Создаем метод инициализации состояний на скрытых слоях\n",
        "  def initialize_hidden_state(self):\n",
        "\n",
        "    # Вернем тензор из нулей размер батча на размер слоя, итсполбьзуем как начальное состояние энкодера\n",
        "    return tf.zeros((self.batch_sz, self.enc_units)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BoTUmLPSsha"
      },
      "source": [
        "Создаем экземпляр класса Encoder. Используем далее как готовый модуль при построении модели сети"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgR4bQIKDFXF"
      },
      "source": [
        "# Создадим модель кодировщика по уже заданным параметрам \n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXH74Z-B_Mmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15bfbc11-0dee-43dd-dcad-8eb4a0fb4c01"
      },
      "source": [
        "# Подадим в качестве примера какой-то сэмпл(Тензор[64, 12]) на вход Encoder'у и визуализируем, что получим\n",
        "sample_hidden = encoder.initialize_hidden_state() #инициализируем начальное скрытое состояние\n",
        "\n",
        "# Даем Encoder'у сэмпл и начальное состояние, и получим выход из сети GRU и состояние на выходе (вызывается метод call класса Encoder)\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Размеры выхода из кодировщика: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Размеры скрытого состояния: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размеры выхода из кодировщика: (batch size, sequence length, units) (256, 12, 1024)\n",
            "Размеры скрытого состояния: (batch size, units) (256, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKRwq1d-S86R"
      },
      "source": [
        "Создадим класс модуля `attenton`, как предписывал Bahdanau. Разбор работы данного модуля мы прошли чуть ранее. На входе состояния кодера `hidden_state` и `values` - выход предыдущего декодера с предыдущего шага. На выходе вектор контекста и веса `attention`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWDTK8eqDHu0"
      },
      "source": [
        "class BahdanauAttention(Model): # Название класса именем создателя механизма Дмитрия Богданова(Bahdanau)\n",
        "\n",
        "  # Создаем конструктор класса\n",
        "  def __init__(self, \n",
        "               units):                        # Число нейронов \n",
        "\n",
        "    super(BahdanauAttention, self).__init__() # Даем возможность использовать и исполнять методы класса-родителя в классе потомке\n",
        "    self.W1 = Dense(units)                    # Создаем Dense с заданным числом нейронов\n",
        "    self.W2 = Dense(units)                    # Создаем Dense с заданным числом нейронов\n",
        "    self.V =  Dense(1)                        # Создаем Dense с числом нейронов =1\n",
        "\n",
        "  # Метод принимает состояние и выход энкодера ----------------------------------\n",
        "  \n",
        "  def call(self, \n",
        "           hidden_state, # Состояние энкодера\n",
        "           values):      # Выход энкодера\n",
        "    # Форма состояния на скрытом слое (batch_size, hidden size)\n",
        "    # Форму состояния на каждом такте увеличим до (batch_size, 1, hidden size)\n",
        "    # Добавляем это для того, чтобы получить оценку\n",
        "    hidden_with_time_axis = tf.expand_dims(hidden_state, 1)\n",
        "\n",
        "    # Форма оценки score (размер батча, макс.длина слов на входе, 1), однёрка в конце, чтобы применить self.V\n",
        "    # До применения self.V оценка была бы (размер батча, макс.длина слов на входе, количество нейронов в слое)\n",
        "    score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # К полученной оценке применим Софтмакс, который покажет вероятность полезности от 0 до 1 для каждого слова в фразе для декодера\n",
        "    # Форма оценки score - (размер батча, макс.длина слов на входе, 1); Софтмакс применяем к оси \"макс.длина слов\"\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # Построим вектор контекста \n",
        "    context_vector = attention_weights * values # Веса внимания перемножим со значениями(выхода из кодировщика)\n",
        "    # Сумму также применяем по оси \"макс.длина слов на входе\"\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1) # Размеры вектора контекста после суммирования будут (размер батча, размер слоя)\n",
        "\n",
        "    # Возвращает вектор контекста и веса внимания\n",
        "    return context_vector, attention_weights\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8sMHv-wU_oD"
      },
      "source": [
        "Создадим экземпляр класса BahdanauAttention. Здесь 10 - число нейронов в первом dense слое"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUv-DSsDDKGl",
        "outputId": "6a701c06-34fc-4b53-a1af-d4c908a6b8f5"
      },
      "source": [
        "# Проверим, как работает слой\n",
        "attention_layer = BahdanauAttention(10)\n",
        "\n",
        "# Подадим на вход слою внимания выход из Encodera и его состояние, и получим значение и веса внимания\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Размеры значения внимания: (размер батча, размер слоя) {}\".format(attention_result.shape))\n",
        "print(\"Размеры весов внимания: (размер батча, длина последовательности, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размеры значения внимания: (размер батча, размер слоя) (256, 1024)\n",
            "Размеры весов внимания: (размер батча, длина последовательности, 1) (256, 12, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK4api1fVM3N"
      },
      "source": [
        "Создаем класс декодера с attention. Декодер принимает обущающую фразу, прогоняет через embedding. Далее склеивает с вектором контента и подает на GRU.\n",
        "На выходе dense слой с числом нейронов равному размеру словаря."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZHTEgDoDNBC"
      },
      "source": [
        "class Decoder(Model):\n",
        "\n",
        "  # Создадим конструктор класса\n",
        "  def __init__(self,   \n",
        "               vocab_size,    # Размер словаря\n",
        "               embedding_dim, # Размерность пространства эмбеддинга\n",
        "               dec_units,     # Число нейронов в GRU\n",
        "               batch_sz):     # Размер батча\n",
        "    super(Decoder, self).__init__()                       # Даем возможность использовать и исполнять методы класса-родителя в классе потомке \n",
        "    self.batch_sz = batch_sz                              # Атрибут возвращает размер батча\n",
        "    self.dec_units = dec_units                            # Атрибут возвращает размер слоя в декодере(кол-во нейронов)\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim) # Атрибут эмбеддинга - слой Кераса с размером словаря на входе и (dim=256) на выходе\n",
        "\n",
        "    # Реккурентной сетью выберем GRU, указываем размер слоя, вывод из слоя в виде последовательностей, \n",
        "    # и метод инициализации весов 'glorot_uniform'(или метод Ксавьера) для упрощения прохождения сигнала при распростр-ии ошибки    \n",
        "    self.gru = GRU(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    self.fc = Dense(vocab_size) # Атрибут вызовет полносвязный слой с размером словаря\n",
        "\n",
        "    self.attention = BahdanauAttention(self.dec_units) #атрибут подключит механизм внимания, описанный ранее\n",
        "\n",
        "\n",
        "  def call(self, \n",
        "           x,           # Начальный токен\n",
        "           hidden,      # Состояние  энкодера\n",
        "           enc_output): # Выход энкодера\n",
        "\n",
        "    # Enc_output размеры (batch_size, max_length, hidden_size - размер батча, макс.длина фраз, разм.скр.слоя)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # Входящий тензор слова пропускаем через эмбеддинг (получаем размеры batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # Дальше конкатенируем с вектором контекста (получаем размеры batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # Сконкатенированный вектор передаем  в GRU и получаем выход с декодера и состояние\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # Output размеры (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # Пропускаем через полносвязный слой\n",
        "    x = self.fc(output) #output размеры (batch_size, vocab)\n",
        "\n",
        "    # Вернем выходную фразу, вектор состояния, веса внимания\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b1yEPu3DPqp",
        "outputId": "d794cf7f-a67f-4000-b4df-7f1b7ee72d13"
      },
      "source": [
        "# Проверим работу декодера, подав на вход случайный массив с нужной размерностью\n",
        "# Создали декодер с параметрами(размер анг.словаря, размерность эмбеддинга, кол-во нейронов, размер батча)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# Подаём на вход случайный массив с нужной размерностью, состояние и выход с кодировщика\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((256, 1)), sample_hidden, sample_output)\n",
        "print ('Размер выхода с декодера: (размер батча, размер словаря) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер выхода с декодера: (размер батча, размер словаря) (256, 11798)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h7uiC6LDVRK"
      },
      "source": [
        "# Выбираем оптимайзер Adam\n",
        "optimizer = Adam() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qw4cgWJlDgW"
      },
      "source": [
        "Наша функция потерь называется  `loss_function` - сначала она уберет из расчетов нулевые элементы в истинной и предсказанной фразе. \n",
        "\n",
        "Длина фразы может быть меньше максимально допустимой или фраза может быть сформирована не полностью. Просто не будем учитывать мусор в конце фразы.\n",
        "\n",
        "Далее применим стандартную для Kerasa функцию потерь  SparseCategoricalCrossentropy. По сравнению CategoricalCrossentropy работает также, но позволяет нам не хранить слова в виде OneHotEncoding, что существенно экономить память.\n",
        "\n",
        "На выходе получаем среднее значение потерь:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YVxy08qDR-5"
      },
      "source": [
        "# Используем SparseCategoricalCrossentropy, к-я может работать с некатегориальными лейблами\n",
        "loss_object = SparseCategoricalCrossentropy(from_logits=True, reduction='none') # Выбираем функцию потерь\n",
        "\n",
        "def loss_function(real, pred):                       # Запишем функцию потерь, на вход подаем фактический и предсказанный результат\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0)) # Найдем маску, которая уберет нулевые значения индексов в конце фразы\n",
        "  loss_ = loss_object(real, pred)                    # Фактические и предсказанные результаты передаем в SparseCategoricalCrossentropy и получаем ошибку\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)            # Согласуем тип маски с типом потерь\n",
        "  loss_ *= mask                                      # Накидываем \"маску\" которая оставит для работы ненулевые значения\n",
        "  \n",
        "  # Вернем reduce_mean - среднее любого выбранного тензора\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHr21E05q0NN"
      },
      "source": [
        "# Сохраняем процесс обучения модели чекпоинтами тензорфлоу\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'                                               # Даем ссылку на директорию\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")                                # Добавляем префикс \"ckpt\"\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder) # Сохраняем состояния/показатели оптимизатора и моделей"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFb7r1SjYf7i"
      },
      "source": [
        "Создадим функцию для обучения модели. На входе - исходная фраза, конечная фраза, начальное состояния кодера. Подаем сразу батчем. На выходе потери на этом батче"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCNvA66Jq7nE"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp,         # Входная фраза\n",
        "               targ,        # Точный перевод\n",
        "               enc_hidden): # Состояния энкодера\n",
        "\n",
        "  # Создаем переменную, в которую будем записывать ошибку\n",
        "  loss = 0                             \n",
        "\n",
        "  # Все операции по вычислению градиента записываются на ленту(tape) и мы получаем к ним доступ\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    # Передаем тензор и начальное состояние в кодировщик и получим выход и состояние на выходе\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    # Передадим это состояние декодеру\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    # Передаем в качестве входа в декодер индекс токена \"<start>\"\n",
        "    dec_input = tf.expand_dims([targ_language_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Техника \"Teacher forcing\" - подаем предыдущее выходное слово на вход следущего в декодере. Targ.shape[64, 9]\n",
        "\n",
        "    for t in range(1, targ.shape[1]): #для каждого слова из английской фразы\n",
        "\n",
        "      # Передаем в обработку декодеру начальный токен, состояние на выходе из кодера, и выход из кодера\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output) # Получаем от декодера предсказание и обновленное состояние\n",
        "\n",
        "      # Обновляем ошибку для текущих предсказаний\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # Используем \"Teacher forcing\"\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  # Получаем ошибку на батче . Targ.shape[64, 9]. Делим на 9\n",
        "  batch_loss = (loss / int(targ.shape[1])) \n",
        "\n",
        "  # Создаем список переменных, для которых TensorFlow будет вычислять градиенты\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables # создаем переменные, для которых TensorFlow будет вычислять градиенты\n",
        "\n",
        "  # Отслеживаем градиент\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  # Корректируем веса\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  # Функция обучения вернет ошибку на батче\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GwOr3sEYiW_"
      },
      "source": [
        "Обучаем сеть. 30 эпох. На каждой эпохе прогоняем весь набор данных через функцию обучения. Считаем лоссы. Сохраняем статистику каждые 10 эпох"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93Tpy6Cxq-V3",
        "outputId": "3699b33a-59e6-4e5d-a2e9-d0364bf549b5"
      },
      "source": [
        "EPOCHS = 30 # устанавливаем количество эпох\n",
        "\n",
        "for epoch in range(EPOCHS): # Цикл по каждой эпохе\n",
        "  start = time.time() # Запомним время начала эпохи\n",
        "\n",
        "  progbar = tf.keras.utils.Progbar(target=steps_per_epoch, stateful_metrics=[\n",
        "                                     'batch_loss'], unit_name='batch')        # Создадим индикатор прогресс обучения\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state() # Задаем начальное состояние на скрытом слое encodera \n",
        "  total_loss = 0                                 # Начальное значение итоговой ошибки\n",
        "\n",
        "  # Для батча, входного и выходного тензора на каждом шаге эпохи\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden) # Передадим в функцию тензоры и состояние в кодировщике, обучим и получим ошибку на батче\n",
        "    total_loss += batch_loss                       # Добавим ее в итоговую ошибку\n",
        "    progbar.update(                                # Обновим состояние индикатора обучения\n",
        "            batch + 1, values=[('batch_loss', batch_loss)])\n",
        "\n",
        "\n",
        "  # Каждые 10 эпох будем сохранять чекпоинты\n",
        "  if (epoch + 1) % 10 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  # Выведем показатели после каждой эпохи\n",
        "  print('Эпоха {} Ошибка {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch)) # Выведем номер эпохи и потери\n",
        "  print('Время на 1 эпоху {} сек'.format(round(time.time() - start), 1))          # Выведем длительность обучения этой эпохи"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 22s 104ms/batch - batch_loss: 2.0914\n",
            "Эпоха 1 Ошибка 2.6452\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 1.8657\n",
            "Эпоха 2 Ошибка 1.9333\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 1.6183\n",
            "Эпоха 3 Ошибка 1.7193\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 105ms/batch - batch_loss: 1.4128\n",
            "Эпоха 4 Ошибка 1.4860\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 105ms/batch - batch_loss: 1.2973\n",
            "Эпоха 5 Ошибка 1.3130\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 1.1695\n",
            "Эпоха 6 Ошибка 1.1815\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 1.0392\n",
            "Эпоха 7 Ошибка 1.0492\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 0.8202\n",
            "Эпоха 8 Ошибка 0.9023\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 0.7313\n",
            "Эпоха 9 Ошибка 0.7378\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 0.5519\n",
            "Эпоха 10 Ошибка 0.5670\n",
            "Время на 1 эпоху 14 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 0.3979\n",
            "Эпоха 11 Ошибка 0.4191\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 103ms/batch - batch_loss: 0.3189\n",
            "Эпоха 12 Ошибка 0.3089\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 0.2413\n",
            "Эпоха 13 Ошибка 0.2310\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 0.1704\n",
            "Эпоха 14 Ошибка 0.1763\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 103ms/batch - batch_loss: 0.1343\n",
            "Эпоха 15 Ошибка 0.1391\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 0.1187\n",
            "Эпоха 16 Ошибка 0.1135\n",
            "Время на 1 эпоху 20 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 0.1168\n",
            "Эпоха 17 Ошибка 0.0946\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 0.0908\n",
            "Эпоха 18 Ошибка 0.0818\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 103ms/batch - batch_loss: 0.0757\n",
            "Эпоха 19 Ошибка 0.0705\n",
            "Время на 1 эпоху 20 сек\n",
            "125/125 [==============================] - 13s 105ms/batch - batch_loss: 0.0579\n",
            "Эпоха 20 Ошибка 0.0637\n",
            "Время на 1 эпоху 14 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 0.0731\n",
            "Эпоха 21 Ошибка 0.0605\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 0.0765\n",
            "Эпоха 22 Ошибка 0.0572\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 0.0627\n",
            "Эпоха 23 Ошибка 0.0527\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 0.0522\n",
            "Эпоха 24 Ошибка 0.0515\n",
            "Время на 1 эпоху 20 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 0.0482\n",
            "Эпоха 25 Ошибка 0.0497\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 0.0720\n",
            "Эпоха 26 Ошибка 0.0482\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 105ms/batch - batch_loss: 0.0564\n",
            "Эпоха 27 Ошибка 0.0477\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 0.0520\n",
            "Эпоха 28 Ошибка 0.0461\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 104ms/batch - batch_loss: 0.0474\n",
            "Эпоха 29 Ошибка 0.0451\n",
            "Время на 1 эпоху 13 сек\n",
            "125/125 [==============================] - 13s 105ms/batch - batch_loss: 0.0630\n",
            "Эпоха 30 Ошибка 0.0442\n",
            "Время на 1 эпоху 14 сек\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzCVG3YhYj0O"
      },
      "source": [
        "Данная функция собирает модель кодера, декодера и attention для работы в режиме перевода (предсказания).\n",
        "\n",
        "На входе переводимое русское предложение, на выходе его английский перевод"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX4koS1irAnJ"
      },
      "source": [
        "def evaluate(sentence):\n",
        "\n",
        "    # Создаем начальные настройки графика внимания\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp)) \n",
        "    \n",
        "    # Предобрабатываем предложение\n",
        "    sentence = preprocess_sentence(sentence) \n",
        "\n",
        "    inputs = [inp_language_tokenizer.word_index[i] for i in sentence.split(' ')]   # Преобразовываем в послед-ть индексов\n",
        "    inputs = pad_sequences([inputs], maxlen=max_length_inp, padding='post')        # Делаем паддинг\n",
        "    inputs = tf.convert_to_tensor(inputs)                                          # Конвертируем в тф тензор\n",
        "\n",
        "    result = ''                                                                    # Сюда запишем результат\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]                                                # Задаем начальное состояние\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)                                  # Передаем его и входной тензор и получаем выход с кодера и состояние\n",
        "\n",
        "    dec_hidden = enc_hidden                                                        # Состояние кодера передаем в декодер\n",
        "    dec_input = tf.expand_dims([targ_language_tokenizer.word_index['<start>']], 0) # Передаем на вход декодеру <start> в виде индекса\n",
        "\n",
        "    for t in range(max_length_targ):                                               # Идем по макс.длине фраз выходного языка(анг)\n",
        "        # Прогоняем через декодер входящий тензор, состояние с выхода кодера, выход с кодера\n",
        "        # Получаем результат предсказания, обновленное состояние, и веса внимания\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "\n",
        "        # Сохраняем веса внимания для графика\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        # Аргмаксом вытаскиваем предсказанное слово\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        # Результат конвертируем из индекса в слово и сохраняем в result = ''\n",
        "        result += targ_language_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        # Если предсказанное слово - <end>, то останавливаемся, возвращаем результаты, выводим на графике\n",
        "        if targ_language_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # Педсказанное значение подается обратно в модель\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    # Вернем перевод, входную фразу и веса внимания\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP7AnPSBcC9D"
      },
      "source": [
        "Нам интересно как связаны слова в исходной фразе и в ее переведе. Функция отрисовывает веса внимания в виде 2D матрицы, соотносит каждую пару  слов  ее весом  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It8ZVMbHrFYj"
      },
      "source": [
        "def plot_attention(attention,           # Веса внимания\n",
        "                   sentence,            # Исходная фраза\n",
        "                   predicted_sentence): # Предсказаные перевод\n",
        "  \n",
        "    fig = plt.figure(figsize=(10,10))                                   # Зададим размер \n",
        "    ax = fig.add_subplot(1, 1, 1)                                       # Добавим 1 картинку\n",
        "    ax.matshow(attention, cmap='viridis')                               # Нарисуем 2d матрицу\n",
        "    fontdict = {'fontsize': 14}                                         # Зададим размер надписей\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90) # Добавим надпись по горизонтальной оси\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)    # Добавим надпись по вертикальной оси\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))               # Зададим форматирование делений на осях графиков\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))               # Зададим форматирование делений на осях графиков\n",
        "    plt.show()                                                          # Отрисуем изображение"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXrttZ_Ccd--"
      },
      "source": [
        "Соберем написанные ранее функции вместе. Будем переводить фразы и строить матрицы внимания(attention)  - смотреть связи слов в предложении"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7afFCab-N_Xf"
      },
      "source": [
        "Создадим функцию для перевода фраз с визуализацией матрицы внимания"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH8G96tWrHmn"
      },
      "source": [
        "def translate(sentence): # Функция принимает предложение и выводит результат с визуализацией\n",
        "    result, sentence, attention_plot = evaluate(sentence)  # Отдадим фразу. Получим перевод, входную фразу,  веса внимания\n",
        "\n",
        "    print('Входящая фраза: %s' % (sentence))          # Выведем входную фразу \n",
        "    print('Предсказанный перевод: {}'.format(result)) # Выведем полученный перевод\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))] # Возьмем весы внимания, только для слов во фразах. Хвосты не смотрим\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))              # Выведем веса внимания"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vsbPAP5rJle",
        "outputId": "8c3ab273-28d9-4d2e-8408-075bb1b6d2d7"
      },
      "source": [
        "# Воспроизведём последний сохранённый чекпоинт\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ffa425ac610>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcH-0rkFPNeU"
      },
      "source": [
        "И, наконец, переведём предложение и выведем визуализацию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "bBi0SqkJrMeK",
        "outputId": "c4fd5f25-24c7-47d0-c0d9-bddccad24cbb"
      },
      "source": [
        "translate('давайте дружить')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Входящая фраза: <start> давайте дружить <end>\n",
            "Предсказанный перевод: let s be friends . <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "X2VVb9LHrOv8",
        "outputId": "95a121e4-64d5-46e7-db6e-bde8459e3923"
      },
      "source": [
        "translate('у тебя всё хорошо')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Входящая фраза: <start> у тебя всё хорошо <end>\n",
            "Предсказанный перевод: your mom is fine . <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "uWC8-1DDrPQ1",
        "outputId": "40c794ee-def5-43b9-94f2-c7c1a493312c"
      },
      "source": [
        "translate('у тебя всё хорошо?')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Входящая фраза: <start> у тебя всё хорошо ? <end>\n",
            "Предсказанный перевод: do you have ok ? <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sahW4uQD51Rv"
      },
      "source": [
        "Что можно сказать. Как переводчик сеть не очень. Но связи слов в предложениях уже находит"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUboNys8E1AX"
      },
      "source": [
        "**Содержание темы**\n",
        "\n",
        "1. [Теория](https://colab.research.google.com/drive/1Bg-UmpEz-T1HcH1CYXH7F4CwJF6asDwa?usp=sharing#scrollTo=ApEBBKSZbVv8)\n",
        "\n",
        "2. Практика\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}